{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\"\"\"Importing dataset and randomising\"\"\"\n",
    "dataset = pd.read_csv('messages', sep='\\t', header=None, names=['Class', 'SMS'])\n",
    "dataset = dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Divide Dataset\"\"\"\n",
    "def divideTable(dataset):\n",
    "    return dataset.iloc[:,1],dataset.iloc[:,0]\n",
    "\n",
    "\"\"\"Split function\"\"\"\n",
    "def split(dataset,trainSize):\n",
    "    return dataset.iloc[:trainSize],dataset.iloc[trainSize:]\n",
    "\n",
    "\"\"\"Removing Punctuations and making letters lowercase\"\"\"\n",
    "def remPuncAndLower(messages):\n",
    "    messages = messages.str.replace('\\W', ' ')\n",
    "    messages = messages.str.lower()\n",
    "    return messages\n",
    "\n",
    "\"\"\"Splitting the messages and making a set of unigrams\"\"\"\n",
    "def makeUnigrams(messages):\n",
    "    messages = messages.str.split()\n",
    "    unigramSet = set()\n",
    "    for i in messages:\n",
    "        for word in i:\n",
    "            unigramSet.add(word)\n",
    "    unigramList = list(set(list(unigramSet)))\n",
    "    return messages, unigramList\n",
    "\n",
    "\"\"\"Calculating frequencies of each unigram\"\"\"\n",
    "def makeFreqUni(unigramList,messages,trainSize):\n",
    "    freqUnigram = dict()\n",
    "    for i in range(len(unigramList)):\n",
    "        freqUnigram[unigramList[i]] = ([0]*trainSize)\n",
    "    \n",
    "    for i in range(len(messages)):\n",
    "        msgList = messages.iloc[i]\n",
    "        for j in msgList:\n",
    "            freqUnigram[j][i] += 1\n",
    "\n",
    "    return pd.DataFrame(freqUnigram)\n",
    "\n",
    "\"\"\"Calculating phi\"\"\"\n",
    "def calcPhi(messages,output,label):\n",
    "    count = 0\n",
    "    for i in range(len(messages)):\n",
    "        if output.iloc[i] == label:\n",
    "            count += 1\n",
    "    return count/len(messages)\n",
    "\n",
    "\"\"\"calculating nos of words in messages of each class\"\"\"\n",
    "def calcNos(x_train,y_train,freqUnigram):\n",
    "    dataset2 = pd.concat([y_train,x_train],axis = 1)\n",
    "    newSet = pd.concat([dataset2,freqUnigram],axis = 1)\n",
    "    \n",
    "    spam = newSet[newSet['Class'] == 'spam']\n",
    "    ham = newSet[newSet['Class'] == 'ham']\n",
    "    n_words_per_spam_message = spam['SMS'].apply(len)\n",
    "    n_spam = n_words_per_spam_message.sum()\n",
    "    n_words_per_ham_message = ham['SMS'].apply(len)\n",
    "    n_ham = n_words_per_ham_message.sum()\n",
    "    \n",
    "    return n_spam,n_ham,spam,ham\n",
    "\n",
    "\"\"\"Classifying test message\"\"\"\n",
    "def classify(testMsg,phiSpam,phiHam,parSpam,parHam):\n",
    "    testMsg = re.sub('\\W', ' ', testMsg)\n",
    "    testMsg = testMsg.lower().split()\n",
    "    \n",
    "    probSpam = phiSpam\n",
    "    probHam = phiHam\n",
    "    \n",
    "    for word in testMsg:\n",
    "        if word in parSpam:\n",
    "            probSpam *= parSpam[word]\n",
    "        if word in parHam:\n",
    "            probHam *= parHam[word]\n",
    "    \n",
    "    if probSpam > probHam:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Splitting into training and test set\"\"\"\n",
    "trainSize = int(0.8*dataset.shape[0])\n",
    "testSize = dataset.shape[0] - trainSize\n",
    "x,y = divideTable(dataset)\n",
    "x_train, x_test = split(x,trainSize)\n",
    "y_train, y_test = split(y,trainSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cleaning training set\"\"\"\n",
    "x_train = remPuncAndLower(x_train)\n",
    "x_train, unigramList = makeUnigrams(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creating dataset of frequency of each unigram\"\"\"\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "freqUnigram = makeFreqUni(unigramList,x_train,trainSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Calculating phi and Nos of words in spam and ham messages\"\"\"\n",
    "phiHam = calcPhi(x_train,y_train,'ham')\n",
    "phiSpam = calcPhi(x_train,y_train,'spam')\n",
    "nSpam,nHam,spam,ham = calcNos(x_train,y_train,freqUnigram)\n",
    "unigramSize = len(unigramList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Calculating Parameters\"\"\"\n",
    "parSpam = {word:0 for word in unigramList}\n",
    "for word in unigramList:\n",
    "    nWSpam = spam[word].sum() \n",
    "    pWSpam = (nWSpam + 1) / (nSpam + 1*unigramSize)\n",
    "    parSpam[word] = pWSpam\n",
    "    \n",
    "parHam = {word:0 for word in unigramList}\n",
    "for word in unigramList:\n",
    "    nWHam = ham[word].sum() \n",
    "    pWHam = (nWHam + 1) / (nHam + 1*unigramSize)\n",
    "    parHam[word] = pWHam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = list()\n",
    "for i in range(len(x_test)):\n",
    "    y_pred.append(classify(x_test.iloc[i],phiSpam,phiHam,parSpam,parHam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is :  98.55334538878843 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_test.iloc[i]:\n",
    "        accuracy += 1\n",
    "print(\"The accuracy of the model is : \",accuracy/testSize * 100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
