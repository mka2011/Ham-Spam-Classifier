{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\"\"\"Importing dataset and randomising\"\"\"\n",
    "dataset = pd.read_csv('messages', sep='\\t', header=None, names=['Class', 'SMS'])\n",
    "dataset = dataset.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Divide Dataset\"\"\"\n",
    "def divideTable(dataset):\n",
    "    return dataset.iloc[:,1],dataset.iloc[:,0]\n",
    "\n",
    "\"\"\"Split function\"\"\"\n",
    "def split(dataset,trainSize):\n",
    "    return dataset.iloc[:trainSize],dataset.iloc[trainSize:]\n",
    "\n",
    "\"\"\"Removing Punctuations and making letters lowercase\"\"\"\n",
    "def remPuncAndLower(messages):\n",
    "    messages = messages.str.replace('\\W', ' ')\n",
    "    messages = messages.str.lower()\n",
    "    return messages\n",
    "\n",
    "\"\"\"Splitting the messages and making a set of unigrams\"\"\"\n",
    "def makeUnigrams(messages):\n",
    "    messages = messages.str.split()\n",
    "    unigramSet = set()\n",
    "    for i in messages:\n",
    "        for word in i:\n",
    "            unigramSet.add(word)\n",
    "    unigramList = list(set(list(unigramSet)))\n",
    "    return messages, unigramList\n",
    "\n",
    "\"\"\"Calculating frequencies of each unigram\"\"\"\n",
    "def makeFreqUni(unigramList,messages,trainSize):\n",
    "    freqUnigram = dict()\n",
    "    for i in range(len(unigramList)):\n",
    "        freqUnigram[unigramList[i]] = ([0]*trainSize)\n",
    "    \n",
    "    for i in range(len(messages)):\n",
    "        msgList = messages.iloc[i]\n",
    "        for j in msgList:\n",
    "            freqUnigram[j][i] += 1\n",
    "\n",
    "    return pd.DataFrame(freqUnigram)\n",
    "\n",
    "\"\"\"Calculating phi\"\"\"\n",
    "def calcPhi(messages,output,label):\n",
    "    count = 0\n",
    "    for i in range(len(messages)):\n",
    "        if output.iloc[i] == label:\n",
    "            count += 1\n",
    "    return count/len(messages)\n",
    "\n",
    "\"\"\"calculating mean of all features for a class\"\"\"\n",
    "def calcMean(data):\n",
    "    meanList = list()\n",
    "    for i in range(2,data.shape[1]):\n",
    "        arr = np.array(data.iloc[:,i])\n",
    "        meanList.append(np.mean(arr))\n",
    "    return meanList\n",
    "    \n",
    "\"\"\"Calculatinf standard deviation of all features of a class\"\"\"    \n",
    "def calcStd(data):\n",
    "    stdList = list()\n",
    "    for i in range(2,data.shape[1]):\n",
    "        arr = np.array(data.iloc[:,i])\n",
    "        stdList.append(np.std(arr))\n",
    "    return stdList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Splitting into training and test set\"\"\"\n",
    "trainSize = int(0.8*dataset.shape[0])\n",
    "testSize = dataset.shape[0] - trainSize\n",
    "x,y = divideTable(dataset)\n",
    "x_train, x_test = split(x,trainSize)\n",
    "y_train, y_test = split(y,trainSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Cleaning training set\"\"\"\n",
    "x_train = remPuncAndLower(x_train)\n",
    "x_train, unigramList = makeUnigrams(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creating dataset of frequency of each unigram\"\"\"\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "freqUnigram = makeFreqUni(unigramList,x_train,trainSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Seprating sets\"\"\"\n",
    "freqUnigram = pd.concat([y_train,x_train,freqUnigram],axis = 1)\n",
    "spam = freqUnigram[freqUnigram['Class'] == 'spam']\n",
    "ham = freqUnigram[freqUnigram['Class'] == 'ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Obtaining phi values, and mean and standrard deviation of each feature\"\"\"\n",
    "phiSpam = len(spam)/len(y_train)\n",
    "phiHam = len(ham)/len(y_train)\n",
    "meanSpam = calcMean(spam)\n",
    "stdSpam = calcStd(spam)\n",
    "meanHam = calcMean(ham)\n",
    "stdHam = calcStd(ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Calculating conditional probability\"\"\"\n",
    "def prob(unigramList,freqTemp,meanList,stdList):\n",
    "    condProb = 1\n",
    "    nfeatures = len(unigramList)\n",
    "    for i in range(nfeatures):\n",
    "        numerator = np.exp(-(((freqTemp[i] - meanList[i])**2)/(2*(stdList[i]**2))+0.1))\n",
    "        denominator = np.sqrt(2*np.pi*(stdList[i]**2)+0.1)\n",
    "        condProb *= (numerator/denominator)\n",
    "    return condProb\n",
    "    \n",
    "\n",
    "\"\"\"Classifying test message\"\"\"\n",
    "def classify(testMsg,unigramList,meanHam,meanSpam,stdHam,stdSpam,phiHam,phiSpam):\n",
    "    testMsg = re.sub('\\W', ' ', testMsg)\n",
    "    testMsg = testMsg.lower().split()\n",
    "    \n",
    "    freqTemp = np.zeros(len(unigramList))\n",
    "    j = 0\n",
    "    for i in unigramList:\n",
    "        if i in testMsg:\n",
    "            freqTemp[j] += 1\n",
    "        j += 1\n",
    "    \n",
    "    probSpam = (prob(unigramList,freqTemp,meanSpam,stdSpam))*phiSpam\n",
    "    probHam = (prob(unigramList,freqTemp,meanHam,stdHam))*phiHam\n",
    "    \n",
    "    if probSpam > probHam:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ham'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_pred = list()\n",
    "for i in range(len(x_test)):\n",
    "    y_pred.append(classify(x_test.iloc[i],unigramList,meanHam,meanSpam,stdHam,stdSpam,phiHam,phiSpam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is :  85.80470162748644 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_test.iloc[i]:\n",
    "        accuracy += 1\n",
    "print(\"The accuracy of the model is : \",accuracy/testSize * 100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
